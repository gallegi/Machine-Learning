{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# 1. Load data:\n- Load train and test set from csv files\n- Split train into train and validation: 70 - 30"},{"metadata":{"trusted":true,"_uuid":"8329b8c50d7cdef33b01aacfb20dd7f22decfc49"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/test.csv\", index_col=0)\n\npd.set_option(\"display.max_rows\", 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6e6e66d048c8acc6b2428e7fa10e06bfae271cd"},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9193106d15fbc008fa26debf0a5bd7e3b0366945"},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59a3d650b8dc92704890068c438a9dc543787c5e"},"cell_type":"markdown","source":"# 2. Data understanding:"},{"metadata":{"trusted":true,"_uuid":"3dd37951932310819bfeb3862410c4a7eb29bdcf"},"cell_type":"code","source":"# man or women survived more?\nsns.barplot(x='Sex',y='Survived',data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8da60eb057c1eada4ea657c163803be728b9c9a"},"cell_type":"code","source":"# Pclass to survived?\nsns.barplot(x='Pclass',y='Survived',data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb8f5c36499c729bc2b7b7070b9448cefe307630"},"cell_type":"code","source":"# Embarked type? Which survived more\nsns.barplot(x='Embarked', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e1bdda40d038c4ffc8b588a27957642225a51ab"},"cell_type":"code","source":"# Sibling types? which survived more\nsns.barplot(x='SibSp', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07f903a967a1a40ec1581ac7a5415da27c8c0be8"},"cell_type":"code","source":"# Parch types? Which survived more\nsns.barplot(x='Parch', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1072b08dd2e9b13063fba27d43dc8a8bb9746e11"},"cell_type":"code","source":"def plot_(col, bins):\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"644d24cb52f0eef5abd89daacccd5090bae4dff2"},"cell_type":"code","source":"temp['Fare'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4479dc5115f7b7c87e22fcc6941863d7437da7af"},"cell_type":"code","source":"a = pd.cut(temp['Fare'], bins=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1862de171a9786fca5c8d53fd78388a888c2eb0"},"cell_type":"code","source":"plt.figure(figsize=(10,10))\ntemp = train.copy()\ntemp['Fare_fact'] = a\n#temp.groupby('Fare').mean()['Survived']\nsns.barplot(x='Fare_fact',y='Survived', data=temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05c22a1f9f86e860019646a1a1d560fdb26655b7"},"cell_type":"code","source":"train.loc[train['Survived']==1].groupby('Pclass').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0c8202a438763320c44d535d7d5dd8bb671a2af"},"cell_type":"code","source":"train['Ticket'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b7f13aec4187443ebbcaef495e52507d6d58988"},"cell_type":"code","source":"train['Ticket'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a55aa33fcaf005d27417efa0a34df0d60fa5eef0"},"cell_type":"code","source":"train.groupby('Ticket').mean().sort_values(by=['Survived'], ascending=False)['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caf28edc5a86dec704fd2b7c84b43a5fa38c8aea"},"cell_type":"code","source":"# correlation\nsns.heatmap(train.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe72459b27cae3bcaac9191753cfb44fa7dbfbd5"},"cell_type":"code","source":"# see the imbalance of the data\nn_class_1 = train.loc[train['Survived']==1, 'Survived'].count()\nn_class_0 = train.loc[train['Survived']==0, 'Survived'].count()\n\nprint(\"Number of survived: \", n_survived)\nprint(\"Number of not survived: \", n_not_survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"418b7bd0528b75839584fa95677be76e38d2ca52"},"cell_type":"markdown","source":"So we conclude that the data is imbalance between class 0 and 1"},{"metadata":{"trusted":true,"_uuid":"0ccbe1428a27f74e3c2470bc126000c37ca554e4"},"cell_type":"markdown","source":"# 3. Data processing:\n- First, deal with missing value\n- 2 methods are used: LabelEncoder and OneHotEncoder for Logistic Regression and Decision Tree repectively"},{"metadata":{"trusted":true,"_uuid":"dcebe7310f730131beec9441e75d4faf3f4b7bc4","scrolled":true},"cell_type":"code","source":"# fillna\ncolumns = train.columns\nfor col in columns:\n    if(train[col].dtype == np.int64 or train[col].dtype == np.float64):\n        train[col] = train[col].fillna(train[col].dropna().median())\n    else:\n        train[col] = train[col].fillna(train[col].dropna().mode()[0])\n        \nfor col in test.columns:\n    if(test[col].dtype == np.int64 or test[col].dtype == np.float64):\n        test[col] = test[col].fillna(test[col].dropna().median())\n    else:\n        test[col] = test[col].fillna(test[col].dropna().mode()[0])\n        \ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f4ef22f4dad6ec9aab9b61e02c9bf8563068398"},"cell_type":"code","source":"# choose which columns to keep\n# drop name columns\n\ntrain_dropname = train.drop(columns=['Name'], axis=1)\ntest_dropname = test.drop(columns=['Name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"673bbe14a358abf47ee4c7dece19693c0099e6ad"},"cell_type":"code","source":"# over sampling to reduce bad effect of imbalance class\ntrain_data_1 = train_dropname.loc[train_dropname['Survived'] == 1].sample(n=n_class_0-n_class_1)\ntrain_data_0 = train_dropname.loc[train_dropname['Survived'] == 0].sample(n=n_class_0)\ntrain_data_ovs = pd.concat([train_dropname.loc[train_dropname['Survived'] == 1], train_data_1, train_data_0])\n\nn_class_0_ovs = len(train_data_ovs.loc[train_data_ovs['Survived'] == 0])\nn_class_1_ovs = len(train_data_ovs.loc[train_data_ovs['Survived'] == 1])\n\nprint(\"Number of class 1 after oversampling: \", n_class_1_ovs)\nprint(\"Number of class 0 after oversampling: \", n_class_0_ovs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3498e423ad4415d3e47449a336ffa2a59fc549d0"},"cell_type":"code","source":"# split train data and train target\ntrain_data = train_data_ovs.drop(columns=['Survived'], axis=1)\ntrain_target = train_data_ovs['Survived']\ntest_data = test_dropname\n\ntest_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ba5c6d1bbd9318c4dfb308b73462f557449d162"},"cell_type":"code","source":"# LabelEncoder\nle = LabelEncoder()\ntrain_test = pd.concat([train_data, test_data], axis=0)\n\ntrain_data_le = train_data.copy()\ntest_data_le = train_data.copy()\n\ncategorical_cols = [ 'Sex', 'Ticket', 'Cabin', 'Embarked']\nfor col in categorical_cols:\n    le.fit(train_test[col])\n    train_data_le[col] = le.transform(train_data[col])\n    test_data_le[col] = le.transform(train_data[col])\n    \ntrain_data_le","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c6c9c11886698b80726a547ae2b3da3e58f2ccd"},"cell_type":"code","source":"sns.heatmap(train_data_le.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59d47d58e65b086db198b5165920cd6b424974f5"},"cell_type":"code","source":"#One hot encoder\ntrain_test = pd.concat([train_data, test_data])\n\n#train_test = train_test.drop(columns=['Fare'], axis=1)\ntrain_test_oh = pd.get_dummies(data=train_test)\n\ntrain_data_oh = train_test_oh.iloc[:len(train_data),:]\ntest_data_oh = train_test_oh.iloc[len(train_data):,:]\n\ntrain_data_oh.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0f8aece53296710f00f2a9cabae8783f68941fb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9083db7cf43f69ef1a1b56f2cfd46688b367adfd"},"cell_type":"code","source":"train_data_oh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bb8e843e91f713fdb3566567bf3a505af8bbc8f"},"cell_type":"markdown","source":"# 4. Using the 3 model to classify\n- LogisticRegression model\n- DecisionTree model\n- Support Vector Machine"},{"metadata":{"trusted":true,"_uuid":"7ad74263325f5f9cc00ec4ac28fa0015c9578a8a","scrolled":false},"cell_type":"code","source":"# linear model\n# logistic regression\nscaler = StandardScaler()\ntrain_data_oh[['Age']] = scaler.fit_transform(train_data_oh[['Age']])\n\nX_train, X_val, y_train, y_val = train_test_split(train_data_oh, train_target, test_size=0.3)\n\nlogistic_model = LogisticRegression(fit_intercept=True, C=100, penalty='l2',solver='newton-cg', \n                                    random_state=3)\nlogistic_model.fit(X_train, y_train)\ntrain_acc = logistic_model.score(X_train, y_train)\nval_acc = logistic_model.score(X_val, y_val)\n\nprint(\"train accuracy: \", train_acc)\nprint(\"validate accuracy: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f1eb7fedb46561e2c105c45ec2f71f70e40c320"},"cell_type":"code","source":"# tree base model\nX_train, X_val, y_train, y_val = train_test_split(train_data_le, train_target, test_size = 0.3)\n\ndt_model = DecisionTreeClassifier(max_depth=10)\ndt_model.fit(X_train, y_train)\ntrain_acc = dt_model.score(X_train, y_train)\nval_acc = dt_model.score(X_val, y_val)\n\nprint(\"train accuracy: \", train_acc)\nprint(\"validate accuracy: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e3fbe2bde312f861ed4ad4d66823db9c8c68933"},"cell_type":"code","source":"# random forest\nX_train, X_val, y_train, y_val = train_test_split(train_data_le, train_target, test_size = 0.3)\n\nrf_model = RandomForestClassifier(max_features=6)\nrf_model.fit(X_train, y_train)\ntrain_acc = rf_model.score(X_train, y_train)\nval_acc = rf_model.score(X_val, y_val)\n\nprint(\"train accuracy: \", train_acc)\nprint(\"validate accuracy: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e78082f2c1e6f3ec63dca8c9be1a86e10e47f3e"},"cell_type":"code","source":"# svm model\nX_train, X_val, y_train, y_val = train_test_split(train_data_oh, train_target, test_size=0.3)\n\nsvm_model = SVC(kernel='linear')\nsvm_model.fit(X_train, y_train)\ntrain_acc = svm_model.score(X_train, y_train)\nval_acc = svm_model.score(X_val, y_val)\n\nprint(\"train accuracy: \", train_acc)\nprint(\"validate accuracy: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b679810e76fe3150f86e7b8df8b573d6fb0ed53a"},"cell_type":"markdown","source":"# 5. Make prediction on test set"},{"metadata":{"trusted":true,"_uuid":"1467fa329417e0e14322f301ff48bfa8a363b3ca"},"cell_type":"code","source":"# retrain on the whole training data\nX = pd.concat([X_train, X_val])\ny = pd.concat([y_train, y_val])\nrf_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf9ebeb8a293431e770b2c4cbe215e11824ac944"},"cell_type":"code","source":"rf_model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"825d2ca163efba3961b8455f65d227ee26effe55"},"cell_type":"code","source":"prediction = svm_model.predict(test_data_oh)\nsubmission = pd.DataFrame({'PassengerId':test.index, 'Survived':prediction})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8b3564f853d8f04c526f78964a3275fc5feafd8"},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b4349a9289551afc2c1ef85551f96488733f631"},"cell_type":"code","source":"# save submission frame\nsubmission.to_csv('submissionv10.csv',index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2764e41a18b842c26e5c14355143e6fb477d4a2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}