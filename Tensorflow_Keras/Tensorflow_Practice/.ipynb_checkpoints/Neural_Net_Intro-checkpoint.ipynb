{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fully connected layer:\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_output = 10\n",
    "\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./dataset/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "mnist = input_data.read_data_sets('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  55000\n",
      "Number of validation examples:  5000\n",
      "Number of testing examples:  10000\n"
     ]
    }
   ],
   "source": [
    "X_train = mnist.train.images\n",
    "X_val = mnist.validation.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels\n",
    "y_val = mnist.validation.labels\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print('Number of training examples: ', X_train.shape[0])\n",
    "print('Number of validation examples: ', X_val.shape[0])\n",
    "print('Number of testing examples: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations to finish 1 epoch:  1719\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "batch_size = 32\n",
    "n_batches = int(np.ceil(X_train.shape[0]/32))\n",
    "print('Number of iterations to finish 1 epoch: ', n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_batch = tf.placeholder(shape=(None, n_inputs), dtype=tf.float32)\n",
    "y_batch = tf.placeholder(shape=(None,), dtype=tf.int64)\n",
    "\n",
    "with tf.name_scope('neural_net'):\n",
    "    hidden1 = tf.layers.dense(inputs=X_batch, units=n_hidden1, activation='relu', name='hidden1')\n",
    "    hidden2 = tf.layers.dense(inputs=hidden1, units=n_hidden2, activation='relu', name='hidden2')\n",
    "    logits = tf.layers.dense(inputs=hidden2, units=n_output, activation=None, name='output')\n",
    "    \n",
    "with tf.name_scope('cost'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_batch, name='xentropy')\n",
    "    loss= tf.reduce_mean(xentropy, name='loss')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y_batch, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    training_op = optimizer.minimize(loss, name='training_op')\n",
    "    \n",
    "# save tf_logs\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "log_dir = \"tf_logs/run-{}\".format(now)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "log_acc = tf.summary.scalar('accuracy', accuracy)\n",
    "log_loss = tf.summary.scalar('XEntropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "training loss:  0.007446749\n",
      "training accuracy:  1.0\n",
      "validation accuracy:  1.0\n",
      "--------------------------------\n",
      "training loss:  0.01492361\n",
      "training accuracy:  1.0\n",
      "validation accuracy:  1.0\n",
      "==================================\n",
      "test accuracy:  0.9715\n"
     ]
    }
   ],
   "source": [
    "# train session:\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for ep in range(n_epochs):\n",
    "        print('--------------------------------')\n",
    "        for batch_index in range(n_batches):\n",
    "            X, y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X_batch:X, \n",
    "                                          y_batch:y})\n",
    "        train_loss = loss.eval(feed_dict={X_batch:X, \n",
    "                                          y_batch:y})\n",
    "        train_accuracy = accuracy.eval(feed_dict={X_batch:X, \n",
    "                                          y_batch:y})\n",
    "        val_accuracy = accuracy.eval(feed_dict={X_batch:X_val, y_batch:y_val})\n",
    "        print(\"training loss: \", train_loss)\n",
    "        print(\"training accuracy: \", train_accuracy)\n",
    "        print(\"validation accuracy: \", train_accuracy)\n",
    "        \n",
    "        # log loss and acc to file\n",
    "        file_writer.add_summary(log_loss.eval(feed_dict={X_batch:X, \n",
    "                                              y_batch:y}))\n",
    "        \n",
    "    test_accuracy = accuracy.eval(feed_dict={X_batch:X_test, y_batch:y_test})\n",
    "    print('==================================')\n",
    "    print('test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
